"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5482],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>u});var o=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);t&&(o=o.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,o)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,o,r=function(e,t){if(null==e)return{};var n,o,r={},a=Object.keys(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(o=0;o<a.length;o++)n=a[o],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=o.createContext({}),c=function(e){var t=o.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},d=function(e){var t=c(e.components);return o.createElement(s.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return o.createElement(o.Fragment,{},t)}},p=o.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),p=c(n),u=r,m=p["".concat(s,".").concat(u)]||p[u]||h[u]||a;return n?o.createElement(m,i(i({ref:t},d),{},{components:n})):o.createElement(m,i({ref:t},d))}));function u(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,i=new Array(a);i[0]=p;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<a;c++)i[c]=n[c];return o.createElement.apply(null,i)}return o.createElement.apply(null,n)}p.displayName="MDXCreateElement"},721:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>h,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var o=n(7462),r=(n(7294),n(3905));const a={},i="Why externalTrafficPolicy: local?",l={unversionedId:"container/components/k8s-cluster-api-provider/doc/LoadBalancer-ExtTrafficLocal",id:"container/components/k8s-cluster-api-provider/doc/LoadBalancer-ExtTrafficLocal",title:"Why externalTrafficPolicy: local?",description:"Setting up the nginx ingress controller from the upstream deployment templates",source:"@site/docs/03-container/components/k8s-cluster-api-provider/doc/LoadBalancer-ExtTrafficLocal.md",sourceDirName:"03-container/components/k8s-cluster-api-provider/doc",slug:"/container/components/k8s-cluster-api-provider/doc/LoadBalancer-ExtTrafficLocal",permalink:"/docs/container/components/k8s-cluster-api-provider/doc/LoadBalancer-ExtTrafficLocal",draft:!1,editUrl:"https://github.com/SovereignCloudStack/docs-page/tree/main/docs/03-container/components/k8s-cluster-api-provider/doc/LoadBalancer-ExtTrafficLocal.md",tags:[],version:"current",frontMatter:{},sidebar:"docs",previous:{title:"Maintenance and Troubleshooting Guide for SCS k8s-cluster-api-provider",permalink:"/docs/container/components/k8s-cluster-api-provider/doc/Maintenance_and_Troubleshooting"},next:{title:"SCS k8s-cluster-api-provider upgrade guide",permalink:"/docs/container/components/k8s-cluster-api-provider/doc/Upgrade-Guide"}},s={},c=[],d={toc:c};function h(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,o.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"why-externaltrafficpolicy-local"},"Why ",(0,r.kt)("inlineCode",{parentName:"h1"},"externalTrafficPolicy: local"),"?"),(0,r.kt)("p",null,"Setting up the nginx ingress controller from the upstream deployment templates\nusing the ",(0,r.kt)("inlineCode",{parentName:"p"},"externalTrafficPolicy: local")," setting and -- without any special\ntreatment -- results in a service that is only partially working: Only requests\nthat the LoadBalancer happens to route at the node where the nginx container is\nrunning get a response."),(0,r.kt)("p",null,"nginx could just use the ",(0,r.kt)("inlineCode",{parentName:"p"},"cluster")," setting instead and kube-proxy would forward\nthe network packets. There are two reasons for nginx not to do that"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Having a load-balancer balance the traffic to a node that is not active just\nto have kube-proxy forward it to the active node does not make much sense.\nIt creates an unecessary hop and makes the LoadBalancer pretty useless.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Packets forwarded by kube-proxy do not carry the original client IP, so any\nsource IP dependant handling in nginx (filtering, QoS, ...) will not be\npossible."))),(0,r.kt)("h1",{id:"getting-it-to-work-for-managed-ingress"},"Getting it to work for managed ingress"),(0,r.kt)("p",null,"There does not seem to be a standard mechanism where k8s tells the LoadBalancer (LB)\nwhich backend members are active, but the load-balancer can find this out by using\na health-monitor that probes for the availability of the service and then takes\nthe inactive nodes out of the rotation. Should the container be rescheduled on\nsome other node, the health-monitor will adapt within a few seconds."),(0,r.kt)("p",null,"Since SCS R2, the deployed nginx-ingress deployment is patched to carry a service\nannotation (OpenStack specific, sigh) that enables the health-monitor for the LB in\nfront of the ingress. This results in traffic to flow."),(0,r.kt)("p",null,"This covers the nginx ingress controller that is deployed by setting",(0,r.kt)("inlineCode",{parentName:"p"},"\n DEPLOY_NGINX_INGRESS: true")," with the ",(0,r.kt)("inlineCode",{parentName:"p"},"create_cluster.sh")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"apply_nginx_ingress.sh"),'.\nThat the ingress we call the "managed ingress".'),(0,r.kt)("p",null,"For the ingress service to see the client IPs, more is needed. The Octavia LB\nas well as the nginx service both support the proxy protocol, which can be used to\ncommunicate the real client IP. We had plumbing included which we disabled by\ndefault prior to releasing R2, because it broke the access to ingress from\nsoftware that runs inside the cluster."),(0,r.kt)("p",null,"A workaround for this has been implemented, so the default is\n",(0,r.kt)("inlineCode",{parentName:"p"},"NGINX_USE_PROXY: true")," as of R4. So the managed nginx ingress service\ndoes work reliably and gets the client IPs."),(0,r.kt)("h1",{id:"getting-it-to-work-in-general"},"Getting it to work in general"),(0,r.kt)("p",null,"Users that deploy their own nginx or other services with ",(0,r.kt)("inlineCode",{parentName:"p"},"externalTrafficPolicy: local"),"\nwon't be helped by the annotations done by the SCS cluster management. They will\nhave to do similar custom patching or revert to a ",(0,r.kt)("inlineCode",{parentName:"p"},"cluster")," policy and forego the\nvisibility on real client IPs."),(0,r.kt)("p",null,"A generic solution to this would be a different kind of LB that does work at the\nnetworking layer 3 (routing), so the (TCP) connections are not terminated at the\nLB and then data being forwarded on a new connection to the backend member, but\nthe routing would create a direct connection. Google (with Direct Server Return, DSR)\nand Azure support such LB modes."),(0,r.kt)("p",null,"As it turns out, on OpenStack clouds that use OVN as networking (SDN) layer, the OVN\nloadbalancer does almost deliver what's needed."),(0,r.kt)("h1",{id:"ovn-provider-loadbalancer"},"OVN provider LoadBalancer"),(0,r.kt)("p",null,"The OVN provider for the load-balancer does create direct flows to the chosen backend\nmember, so no proxy protocol (or similar hacks) are needed to make the backend service\nsee the client IPs. This has been validated (and can even be monitored by openstack-health-monitor)\non SCS clouds that use OVN."),(0,r.kt)("p",null,"A health-monitor is still needed to ensure that only active members receive requests.\nThere are unfortunately two problems with the health-monitoring on the OVN provider:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The health-monitor does correctly detect members that are not responding and stops\nrouting traffic from the VIP towards the inactive member. Unfortunately the\ntraffic that comes in from the floating IP associated with the VIP is not treated\nthe same, but is still distributed to the inactive members, resulting in a good\nfraction of the requests to go unanswered. This is tracked in bug\n",(0,r.kt)("a",{parentName:"li",href:"https://bugs.launchpad.net/neutron/+bug/1956035"},"https://bugs.launchpad.net/neutron/+bug/1956035")),(0,r.kt)("li",{parentName:"ul"},"The OCCM always tries to create an HTTP health-monitor. The OVN provider however\ndoes not yet support HTTP health-monitors, only TCP. We'll have to wait for (and\npossibly help with) HTTP health-monitors to be implemented upstream.")),(0,r.kt)("p",null,"Due to the HTTP health-monitor not being supported, the created loadbalancer is not\nconsidered functional, so the reconciliation loop creates another loadbalancer until\nyour project runs into quota limits (on the loadbalancer or on ports).\nSo for now, the feature ",(0,r.kt)("inlineCode",{parentName:"p"},"use_ovn_lb_provider")," should not be enabled."),(0,r.kt)("p",null,"Note that the ",(0,r.kt)("inlineCode",{parentName:"p"},"use_ovn_lb_provider")," does not affect the LB in front of the kube API.\nThat one is created by capo and requires other settings. Also note that it would\nnot yet support the CIDR filtering with ",(0,r.kt)("inlineCode",{parentName:"p"},"restrict_kubeapi")," setting."),(0,r.kt)("h1",{id:"enabling-health-monitor-by-default"},"Enabling health-monitor by default?"),(0,r.kt)("p",null,"We could enable a health-monitor by default for load-balancers created from OCCM\nin the k8s clusters. This would make services with ",(0,r.kt)("inlineCode",{parentName:"p"},"externalTrafficPolicy: local"),"\nwork, as the traffic would be routed exclusively to active members. But the\nother goal would not be achieved: Getting the real client IPs.\nWe decided against turning on the health-monitor by default, as this might result\nin the wrong impression that ",(0,r.kt)("inlineCode",{parentName:"p"},"local")," fully works. Rather break and then have users take\na decision to go for ",(0,r.kt)("inlineCode",{parentName:"p"},"cluster"),", to enable health-monitoring to get it half-working\nor to do health-monitoring plus some extra plumbing for proxy protocol (or similar)\nto get all aspects working."))}h.isMDXComponent=!0}}]);